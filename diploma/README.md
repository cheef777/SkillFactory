# Проект. Виртуальный коуч.

## Выполнил: Плюснин О.Л.

В этом проекте мы создаем виртуального коуча, способного анализировать действия человека на видео с помощью распознавания действия по ключевым точкам, обнаруженным на теле человека. В итоге каждый пользователь сможет примерить на себя роль первоклассного тренера!

Для создания Human Pose Skeleton можно воспользоваться архитектурой **Keypoint RCNN**, имплементация которой представлена в библиотеке torchvision(keypointrcnn_resnet50_fpn).

Модель обучена на наборе данных MS-COCO (Common Objects in Context) с целью обнаружения 17 ключевых точек человеческого тела (нос, глаза, уши, плечи, локти, запястья, бёдра, колени и лодыжки).

<image src="dspr_cv_u1_diploma_spr2_1_1.png">
<br>
<br>  
Архитектура **Keypoint RCNN** представлена на рисунке ниже.


<kbd>
<image src="dspr_cv_u1_diploma_spr1_2_1.png">
</kbd>
<br>
<br>

> Модель выводит список из следующих элементов:   
* **boxes** — тензор размера [N, 4], где N — количество обнаруженных объектов.   
* **labels** — тензор размера [N], класс объекта. Он всегда равен 1, так как каждый обнаруженный «ящик» указывает на человека. 0 обозначает фоновый класс.   
* **scores** — тензор размера [N], отображающий показатель достоверности обнаруженного объекта.   
* **keypoints** — тензор размера [N, 17, 3], отображающий 17 ключевых точек N человек. Первые два числа — координаты x и y, а третье — видимость.   
* **keypoints_scores** — тензор размера [N, 17], отражающий оценку всех ключевых точек для каждого обнаруженного человека.   

Keypoint RCNN имеет готовую реализацию в обёртке PyTorch. С помощью данной модели мы без труда детектируем ключевые точки человеческого тела (от глаз до лодыжек) на изображении, а также получаем степень достоверности этих обнаружений.

Для корректного расчета метрик изображение тренирующегося приводится к тренерскому аффинным преобразованием с помощью метода наименьших квадратов.
   

Благодаря алгоритмам сходства, таким как косинусное сходство и взвешенное совпадение, мы можем анализировать близость между двумя оценками позы человека. Сходство косинуса рассчитывается путём создания векторов поз и оценки косинуса угла между ними. Взвешенное совпадение учитывают оценку достоверности каждой отдельно найденной ключевой точки так, чтобы более реалистичные ключевые точки в большей степени влияли на результат.

> Программа для более качественного вычисления метрик использует обрезание позы с помощью **boxes** и пересчитывает координаты ключевых точек с началом координат в центре изображения.

Программа на вход принимает два видеофайла в формате .mp4 или .avi размером видео 1280X720 с одинаковым fps. Первый видеофайл с записью выполнения упражнения тренером, второй - запись вашего выполнения.
Путь к файлам прописывается в константах PATH_IMAGE_TRUE и PATH_IMAGE_TRAIN соответственно. Программа сравнивает два видефайла и считает метрики. На выходе мы получаем видеофайл в формате .avi с размером кадра 1280X720 с тем же fps, что и исходные файлы. Выходной видеофайл содержит изображение выполнения упражнения тренером (сверху) и Ваше (снизу), под изображениями выводятся значения метрик. Путь к файлу прописывается в константе PATH_IMAGE_OUT.

> При работе программа создает папку **video_out** для хранения фреймов выходного видеофайла.

<br>
<br>


### Что можно улучшить?

+ Прграмма пока не работает со входными видео различающиеся по FPS и размеру кадра.
+ В выходном видео нужно улучшить кадрирование фреймов.
+ Вместо косинусного расстояния, которое очень близко к единице, лучше было бы использовать значения непосредственно углов между векторами в градусах.
+ Ввести критерий для расчета конкретной оценки выполнения упражнения в баллах и отображать его.






